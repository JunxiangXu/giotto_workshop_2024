[["index.html", "Workshop: Spatial multi-omics data analysis with Giotto Suite 1 Giotto Workshop 2024 1.1 Instructors 1.2 Topics and Schedule: 1.3 License", " Workshop: Spatial multi-omics data analysis with Giotto Suite Ruben Dries, Jiaji George Chen, Joselyn Cristina Chávez-Fuentes, Junxiang Xu ,Edward Ruiz, Jeff Sheridan, Iqra Amin, Wen Wang 1 Giotto Workshop 2024 Workshop: Spatial multi-omics data analysis with Giotto Suite 1.1 Instructors Ruben Dries: Assistant Professor of Medicine at Boston University Joselyn Cristina Chávez Fuentes: Postdoctoral fellow at Icahn School of Medicine at Mount Sinai Jiaji George Chen: Ph.D. student at Boston University Junxiang Xu: Ph.D. student at Boston University Edward C. Ruiz: Ph.D. student at Boston University Jeff Sheridan: Postdoctoral fellow at Boston University Iqra Amin: Bioinformatician Wen Wang: Postdoctoral fellow at Icahn School of Medicine at Mount Sinai 1.2 Topics and Schedule: Day 1: Introduction Spatial omics technologies Spatial sequencing Spatial in situ Spatial proteomics spatial other: ATAC-seq, lipidomics, etc Introduction to the Giotto package Ecosystem Installation + python environment Giotto instructions Data formatting and Pre-processing Creating a Giotto object From matrix + locations From subcellular raw data (transcripts or images) + polygons Using convenience functions for popular technologies (Vizgen, Xenium, CosMx, …) Spatial plots Subsetting: Based on IDs Based on locations Visualizations Introduction to spatial multi-modal dataset (10X Genomics breast cancer) and goal for the next days Quality control Statistics Normalization Feature selection: Highly Variable Features: loess regression binned pearson residuals Spatial variable genes Dimension Reduction PCA UMAP/t-SNE Visualizations Clustering Non-spatial k-means Hierarchical clustering Leiden/Louvain Spatial Spatial variable genes Spatial co-expression modules Day 2: Spatial Data Analysis Spatial sequencing based technology: Visium Differential expression Enrichment &amp; Deconvolution PAGE/Rank SpatialDWLS Visualizations Interactive tools Spatial expression patterns Spatial variable genes Spatial co-expression modules Spatial HMRF Spatial sequencing based technology: Visium HD Tiling and aggregation Scalability (duckdb) and projection functions Spatial expression patterns Spatial co-expression module Spatial in situ technology: Xenium Read in raw data Transcript coordinates Polygon coordinates Visualizations Overlap txs &amp; polygons Typical aggregated workflow Feature/molecule specific analysis Visualizations Transcript enrichment GSEA Spatial location analysis Spatial cell type co-localization analysis Spatial niche analysis Spatial niche trajectory analysis Visualizations Spatial proteomics: multiplex IF Read in raw data Intensity data (IF or any other image) Polygon coordinates Visualizations Overlap intensity &amp; workflows Typical aggregated workflow Visualizations Day 3: Advanced Tutorials Multiple samples Create individual giotto objects Join Giotto Objects Perform Harmony and default workflows Visualizations Spatial multi-modal Co-registration of datasets Examples in giotto suite manuscript Multi-omics integration Example in giotto suite manuscript Interoperability w/ other frameworks AnnData/SpatialData SpatialExperiment Seurat Interoperability w/ isolated tools Spatial niche trajectory analysis Interactivity with the R/Spatial ecosystem Kriging Contributing to Giotto 1.3 License This material has a Creative Commons Attribution-ShareAlike 4.0 International License. To get more information about this license, visit http://creativecommons.org/licenses/by-sa/4.0/ "],["spatial-omics-technologies.html", "2 Spatial omics technologies 2.1 Slides 2.2 Spatial sequencing 2.3 Spatial in situ 2.4 Spatial proteomics 2.5 Other Spatial omics: ATAC-seq, CUT&amp;RUN, lipidomics, etc", " 2 Spatial omics technologies Ruben Dries August 5th 2024 2.1 Slides 2.2 Spatial sequencing 2.3 Spatial in situ 2.4 Spatial proteomics 2.5 Other Spatial omics: ATAC-seq, CUT&amp;RUN, lipidomics, etc "],["introduction-to-the-giotto-package.html", "3 Introduction to the Giotto package 3.1 Slides 3.2 Ecosystem 3.3 Installation + python environment 3.4 Giotto instructions", " 3 Introduction to the Giotto package Ruben Dries &amp; Jiaji George Chen August 5th 2024 3.1 Slides 3.2 Ecosystem 3.3 Installation + python environment 3.4 Giotto instructions "],["data-formatting-and-pre-processing.html", "4 Data formatting and Pre-processing 4.1 Data formats 4.2 Pre-processing", " 4 Data formatting and Pre-processing Jiaji George Chen August 5th 2024 save_dir &lt;- &quot;~/Documents/GitHub/giotto_workshop_2024/img/01_session3&quot; 4.1 Data formats .h5 .mtx - get10xmatrix .parquet .csv/.tsv - fread .json -jsonlite .geojson .tiff/.ome.tif 4.2 Pre-processing necessary additional packages? "],["creating-a-giotto-object.html", "5 Creating a Giotto object 5.1 Overview 5.2 From matrix + locations 5.3 From subcellular raw data (transcripts or images) + polygons 5.4 From piece-wise 5.5 Using convenience functions for popular technologies (Vizgen, Xenium, CosMx, …) 5.6 Spatial plots 5.7 Subsetting 5.8 Mini objects &amp; GiottoData", " 5 Creating a Giotto object Jiaji George Chen August 5th 2024 save_dir &lt;- &quot;~/Documents/GitHub/giotto_workshop_2024/img/01_session4&quot; 5.1 Overview Giotto has representations for both aggregated (cell by count) + xy(z) information and subcellular polygon or mask information and transcript xy(z) or image information. A Giotto object can be set up from either of the two above sets of information. 5.2 From matrix + locations createGiottoObject() 5.3 From subcellular raw data (transcripts or images) + polygons createGiottoObjectSubcellular() The above two methods accept data, converts them into Giotto’s compatible formats, and then assembles the final giotto object. If desired you can also assemble a giotto object piece-wise after creating the Giotto subobjects manually. 5.4 From piece-wise g &lt;- giotto() g &lt;- setGiotto(g, ??) 5.5 Using convenience functions for popular technologies (Vizgen, Xenium, CosMx, …) There are also several convenience functions we provide for loading in data from popular platforms. Many of these will be touched on later during other sessions createGiottoVisiumObject() createGiottoVisiumHDObject() createGiottoXeniumObject() createGiottoCosMxObject() createGiottoMerscopeObject() 5.6 Spatial plots Giotto has several spatial plotting functions. At the lowest level, you directly call plot() on several subobjects in order to see what they look like, particularly the ones containing spatial info. gpoints &lt;- GiottoData::loadSubObjectMini(&quot;giottoPoints&quot;) gpoly &lt;- GiottoData::loadSubObjectMini(&quot;giottoPolygon&quot;) spatlocs &lt;- GiottoData::loadSubObjectMini(&quot;spatLocsObj&quot;) spatnet &lt;- GiottoData::loadSubObjectMini(&quot;spatialNetworkObj&quot;) pca &lt;- GiottoData::loadSubObjectMini(&quot;dimObj&quot;) plot(pca, dims = c(3,10)) 5.7 Subsetting Based on IDs Based on locations Visualizations 5.8 Mini objects &amp; GiottoData Giotto makes available several mini objects to allow devs and users to work with easily loadable Giotto objects. These are small subsets of a larger dataset that often contain some worked through analyses and are fully functional. pak::pak(&quot;drieslab/GiottoData&quot;) "],["visium-part-i.html", "6 Visium Part I 6.1 Introduction to the spatial dataset 6.2 Download dataset 6.3 Create the Giotto object 6.4 Subset on spots that were covered by tissue 6.5 Quality control 6.6 Filtering 6.7 Normalization 6.8 Feature selection 6.9 Dimension Reduction 6.10 Clustering 6.11 Save the object 6.12 Session info", " 6 Visium Part I Joselyn Cristina Chávez Fuentes August 5th 2024 6.1 Introduction to the spatial dataset The Visium brain data to run this tutorial can be found here 6.2 Download dataset You need to download the expression matrix and spatial information by running these commands: dir.create(&quot;data&quot;) download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Adult_Mouse_Brain/V1_Adult_Mouse_Brain_raw_feature_bc_matrix.tar.gz&quot;, destfile = &quot;data/V1_Adult_Mouse_Brain_raw_feature_bc_matrix.tar.gz&quot;) download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/1.1.0/V1_Adult_Mouse_Brain/V1_Adult_Mouse_Brain_spatial.tar.gz&quot;, destfile = &quot;data/V1_Adult_Mouse_Brain_spatial.tar.gz&quot;) After downloading, unzip the gz files. You should get the “raw_feature_bc_matrix” and “spatial” folders inside “data/”. 6.3 Create the Giotto object library(Giotto) ## Set instructions results_folder &lt;- &quot;results/&quot; python_path &lt;- NULL instructions &lt;- createGiottoInstructions( save_dir = results_folder, save_plot = TRUE, show_plot = FALSE, return_plot = FALSE, python_path = python_path ) ## Provide the path to the visium folder data_path &lt;- &quot;data&quot; ## Create object directly from the visium folder visium_brain &lt;- createGiottoVisiumObject( visium_dir = data_path, expr_data = &quot;raw&quot;, png_name = &quot;tissue_lowres_image.png&quot;, gene_column_index = 2, instructions = instructions ) 6.4 Subset on spots that were covered by tissue spatPlot2D( gobject = visium_brain, cell_color = &quot;in_tissue&quot;, point_size = 2, cell_color_code = c(&quot;0&quot; = &quot;lightgrey&quot;, &quot;1&quot; = &quot;blue&quot;), show_image = TRUE, image_name = &quot;image&quot; ) metadata &lt;- getCellMetadata(gobject = visium_brain, output = &quot;data.table&quot;) in_tissue_barcodes &lt;- metadata[in_tissue == 1]$cell_ID visium_brain &lt;- subsetGiotto(gobject = visium_brain, cell_ids = in_tissue_barcodes) 6.5 Quality control Statistics visium_brain_statistics &lt;- addStatistics(gobject = visium_brain, expression_values = &quot;raw&quot;) ## visualize spatPlot2D(gobject = visium_brain_statistics, cell_color = &quot;nr_feats&quot;, color_as_factor = FALSE) filterDistributions(gobject = visium_brain_statistics, detection = &quot;cells&quot;) filterDistributions(gobject = visium_brain_statistics, detection = &quot;feats&quot;) filterCombinations() may be used to test how different filtering parameters will affect the number of cells and features in the filtered data: filterCombinations(gobject = visium_brain_statistics, expression_thresholds = c(1, 2, 3), feat_det_in_min_cells = c(50, 100, 200), min_det_feats_per_cell = c(500, 1000, 1500)) 6.6 Filtering visium_brain &lt;- filterGiotto( gobject = visium_brain, expression_threshold = 1, feat_det_in_min_cells = 50, min_det_feats_per_cell = 1000, expression_values = &quot;raw&quot;, verbose = TRUE ) Feature type: rna Number of cells removed: 4 out of 2702 Number of feats removed: 7311 out of 22125 6.7 Normalization visium_brain &lt;- normalizeGiotto( gobject = visium_brain, scalefactor = 6000, verbose = TRUE ) visium_brain &lt;- addStatistics(gobject = visium_brain) ## visualize spatPlot2D(gobject = visium_brain, cell_color = &quot;nr_feats&quot;, color_as_factor = FALSE) 6.8 Feature selection 6.8.1 Highly Variable Features: Calculating Highly Variable Features (HVF) is necessary to identify genes (or features) that display significant variability across spatial locations. There are a few methods to choose from: loess regression visium_brain &lt;- calculateHVF(gobject = visium_brain, method = &quot;cov_loess&quot;, save_plot = TRUE, default_save_name = &quot;HVFplot_loess&quot;) pearson residuals visium_brain &lt;- calculateHVF(gobject = visium_brain, method = &quot;var_p_resid&quot;, save_plot = TRUE, default_save_name = &quot;HVFplot_pearson&quot;) binned visium_brain &lt;- calculateHVF(gobject = visium_brain, method = &quot;cov_groups&quot;, save_plot = TRUE, default_save_name = &quot;HVFplot_binned&quot;) Depending on the underlying distribution of the data: loess regression is used when the relationship between mean expression and variance is non-linear or can be described by a non-parametric model pearson residuals are used when the relationship between mean expression and variance is linear or can be described by a parametric model binned (covariance groups) are used when variability in gene expression differs across expression levels or spatial regions, without assuming a specific relationship between mean expression and variance 6.9 Dimension Reduction 6.9.1 PCA Principal Components Analysis (PCA) is applied to reduce the dimensionality of gene expression data by transforming it into principal components, which are linear combinations of genes ranked by the variance they explain, with the first components capturing the most variance. Default visium_brain &lt;- runPCA(gobject = visium_brain) Using specific features my_features &lt;- head(getFeatureMetadata(visium_brain, output = &quot;data.table&quot;)$feat_ID, 1000) visium_brain &lt;- runPCA(gobject = visium_brain, feats_to_use = my_features, name = &quot;custom_pca&quot;) Visualization Screeplot screePlot(gobject = visium_brain, ncp = 30) PCA plotPCA(gobject = visium_brain) Custom PCA plotPCA(gobject = visium_brain, dim_reduction_name = &quot;custom_pca&quot;) Unlike PCA, Unifold Manifold Approximation and Projection (UMAP) and t-Stochastic Neighbor Embedding (t-SNE) do not assume linearity. After running PCA, UMAP or t-SNE follows to further reduce PCs. 6.9.2 UMAP visium_brain &lt;- runUMAP(visium_brain, dimensions_to_use = 1:10) Visualization plotUMAP(gobject = visium_brain) 6.9.3 t-SNE visium_brain &lt;- runtSNE(gobject = visium_brain, dimensions_to_use = 1:10) Visualization plotTSNE(gobject = visium_brain) UMAP generally provides a more balanced view of spatial relationships and biological context, while t-SNE can be more effective in highlighting specific clusters or spatially proximal groups. 6.10 Clustering Shared Nearest Neighbor (sNN) emphasizes local coherence by considering spots that share nearest neighbors, highlighting cohesive spatial structures in the data. k-Nearest Neighbors (kNN) defines spatial relationships based on direct proximity, focusing on the nearest neighbors of each spot without considering shared neighborhood patterns as explicitly as sNN. Create a sNN network (default) visium_brain &lt;- createNearestNetwork(gobject = visium_brain, dimensions_to_use = 1:10, k = 15) Create a kNN network visium_brain &lt;- createNearestNetwork(gobject = visium_brain, dimensions_to_use = 1:10, k = 15, type = &quot;kNN&quot;) 6.10.1 Calculate Leiden clustering visium_brain &lt;- doLeidenCluster(gobject = visium_brain, resolution = 0.4, n_iterations = 1000) Visualization plotPCA(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;) plotUMAP(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, show_NN_network = FALSE, point_size = 2.5) plotUMAP(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, show_NN_network = TRUE, point_size = 2.5) plotTSNE(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, point_size = 2.5) plotTSNE(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, point_size = 2.5, show_NN_network = TRUE) Dimension plots grouped by cluster spatPlot2D(visium_brain, cell_color = &quot;leiden_clus&quot;) 6.10.2 Calculate Louvain clustering visium_brain &lt;- doLouvainCluster(visium_brain) spatPlot2D(visium_brain, cell_color = &quot;louvain_clus&quot;) Leiden clustering is generally preferred for larger and more complex datasets, where as Louvain clustering may be suitable for more smaller datasets or scenarios where computational efficiency is a priority. 6.11 Save the object saveGiotto(visium_brain, &quot;visium_brain_object&quot;) 6.12 Session info sessionInfo() "],["visium-part-ii.html", "7 Visium Part II 7.1 Load the object 7.2 Differential expression 7.3 Enrichment &amp; Deconvolution 7.4 Spatial expression patterns 7.5 Spatially informed clusters 7.6 Spatial domains HMRF 7.7 Interactive tools 7.8 Session info", " 7 Visium Part II Joselyn Cristina Chávez Fuentes August 6th 2024 7.1 Load the object library(Giotto) visium_brain &lt;- loadGiotto(&quot;visium_brain_object&quot;) 7.2 Differential expression 7.2.1 Gini markers Calculate the top marker genes per cluster using the gini method gini_markers &lt;- findMarkers_one_vs_all(gobject = visium_brain, method = &quot;gini&quot;, expression_values = &quot;normalized&quot;, cluster_column = &quot;leiden_clus&quot;, min_feats = 10) topgenes_gini &lt;- gini_markers[, head(.SD, 2), by = &quot;cluster&quot;]$feats Visualize violinPlot(visium_brain, feats = unique(topgenes_gini), cluster_column = &quot;leiden_clus&quot;, strip_text = 6, strip_position = &quot;right&quot;, save_param = list(base_width = 5, base_height = 30)) plotMetaDataHeatmap(visium_brain, selected_feats = unique(topgenes_gini), metadata_cols = &quot;leiden_clus&quot;, x_text_size = 10, y_text_size = 10) dimFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, feats = sort(unique(topgenes_gini)), cow_n_col = 5, point_size = 1, save_param = list(base_width = 15, base_height = 20)) 7.2.2 Scran markers Calculate the top marker genes per cluster using the scran method scran_markers &lt;- findMarkers_one_vs_all(gobject = visium_brain, method = &quot;scran&quot;, expression_values = &quot;normalized&quot;, cluster_column = &quot;leiden_clus&quot;, min_feats = 10) topgenes_scran &lt;- scran_markers[, head(.SD, 2), by = &quot;cluster&quot;]$feats Visualize violinPlot(visium_brain, feats = unique(topgenes_scran), cluster_column = &quot;leiden_clus&quot;, strip_text = 6, strip_position = &quot;right&quot;, save_param = list(base_width = 5, base_height = 30)) plotMetaDataHeatmap(visium_brain, selected_feats = unique(topgenes_scran), metadata_cols = &quot;leiden_clus&quot;, x_text_size = 10, y_text_size = 10) dimFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, feats = sort(unique(topgenes_scran)), cow_n_col = 5, point_size = 1, save_param = list(base_width = 20, base_height = 20)) The Gini method is preferred when identifying genes that exhibit significant expression differences across clusters, highlighting genes with distinct expression patters between different clusters. The Scran method is preferred for robust differential expression analysis, especially when addressing technical variability or differences in sequencing depth across spatial locations. In practice, it is often beneficial to apply both methods and compare results for a more complete understanding of differential gene expression across clusters. 7.3 Enrichment &amp; Deconvolution Visium spatial transcriptomics does not provide single-cell resolution, making cell type annotation a harder problem. Giotto provides several ways to calculate enrichment of specific cell-type signature gene lists. Download the single-cell dataset GiottoData::getSpatialDataset(dataset = &quot;scRNA_mouse_brain&quot;, directory = &quot;data/&quot;) Create the single-cell object results_folder &lt;- &quot;results/&quot; python_path &lt;- NULL instructions &lt;- createGiottoInstructions( save_dir = results_folder, save_plot = TRUE, show_plot = FALSE, python_path = python_path ) sc_expression &lt;- &quot;data/brain_sc_expression_matrix.txt.gz&quot; sc_metadata &lt;- &quot;data/brain_sc_metadata.csv&quot; giotto_SC &lt;- createGiottoObject(expression = sc_expression, instructions = instructions) giotto_SC &lt;- addCellMetadata(giotto_SC, new_metadata = data.table::fread(sc_metadata)) giotto_SC &lt;- normalizeGiotto(giotto_SC) 7.3.1 PAGE/Rank Parametric Analysis of Gene Set Enrichment (PAGE) and Rank enrichment both aim to determine whether a predefined set of genes show statistically significant differences in expression compared to other genes in the dataset. Calculate the cell type markers markers_scran &lt;- findMarkers_one_vs_all(gobject = giotto_SC, method = &quot;scran&quot;, expression_values = &quot;normalized&quot;, cluster_column = &quot;Class&quot;, min_feats = 3) top_markers &lt;- markers_scran[, head(.SD, 10), by = &quot;cluster&quot;] celltypes &lt;- levels(factor(markers_scran$cluster)) Create the signature matrix sign_list &lt;- list() for (i in 1:length(celltypes)){ sign_list[[i]] = top_markers[which(top_markers$cluster == celltypes[i]),]$feats } sign_matrix &lt;- makeSignMatrixPAGE(sign_names = celltypes, sign_list = sign_list) Run the enrichment test with PAGE visium_brain &lt;- runPAGEEnrich(gobject = visium_brain, sign_matrix = sign_matrix) Visualize cell_types_PAGE &lt;- colnames(sign_matrix) plotMetaDataCellsHeatmap(gobject = visium_brain, metadata_cols = &quot;leiden_clus&quot;, value_cols = cell_types_PAGE, spat_enr_names = &quot;PAGE&quot;, x_text_size = 8, y_text_size = 8) spatCellPlot2D(gobject = visium_brain, spat_enr_names = &quot;PAGE&quot;, cell_annotation_values = cell_types_PAGE, cow_n_col = 3, coord_fix_ratio = 1, point_size = 1, show_legend = TRUE) 7.3.2 SpatialDWLS Spatial Diffusion Weighted Least Squares (DWLS) estimates the proportions of different cell types or spatial gradients of gene expression across spots in a tissue. Create the signature matrix sign_matrix &lt;- makeSignMatrixDWLSfromMatrix( matrix = getExpression(giotto_SC, values = &quot;normalized&quot;, output = &quot;matrix&quot;), cell_type = pDataDT(giotto_SC)$Class, sign_gene = top_markers$feats) Run the DWLS Deconvolution visium_brain &lt;- runDWLSDeconv(gobject = visium_brain, sign_matrix = sign_matrix) Visualize # Plot DWLS deconvolution result with Pie plots spatDeconvPlot(visium_brain, show_image = FALSE, radius = 50, save_param = list(save_name = &quot;8_spat_DWLS_pie_plot&quot;)) 7.4 Spatial expression patterns 7.4.1 Spatial variable genes Create a spatial network visium_brain &lt;- createSpatialNetwork(gobject = visium_brain, method = &quot;kNN&quot;, k = 6, maximum_distance_knn = 400, name = &quot;spatial_network&quot;) spatPlot2D(gobject = visium_brain, show_network= TRUE, network_color = &quot;blue&quot;, spatial_network_name = &quot;spatial_network&quot;) Rank binarization ranktest &lt;- binSpect(visium_brain, bin_method = &quot;rank&quot;, calc_hub = TRUE, hub_min_int = 5, spatial_network_name = &quot;spatial_network&quot;) Visualize top results spatFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, feats = ranktest$feats[1:6], cow_n_col = 2, point_size = 1) 7.4.2 Spatial co-expression modules Cluster the top 500 spatial genes into 20 clusters ext_spatial_genes &lt;- ranktest[1:500,]$feats Use detectSpatialCorGenes function to calculate pairwise distances between genes. spat_cor_netw_DT &lt;- detectSpatialCorFeats( visium_brain, method = &quot;network&quot;, spatial_network_name = &quot;spatial_network&quot;, subset_feats = ext_spatial_genes) Identify most similar spatially correlated genes for one gene top10_genes &lt;- showSpatialCorFeats(spat_cor_netw_DT, feats = &quot;Mbp&quot;, show_top_feats = 10) Visualize spatFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, feats = top10_genes$variable[1:4], point_size = 1.5) Cluster spatial genes spat_cor_netw_DT &lt;- clusterSpatialCorFeats(spat_cor_netw_DT, name = &quot;spat_netw_clus&quot;, k = 20) Visualize clusters heatmSpatialCorFeats(visium_brain, spatCorObject = spat_cor_netw_DT, use_clus_name = &quot;spat_netw_clus&quot;, heatmap_legend_param = list(title = NULL)) Rank spatial correlated clusters and show genes for selected clusters netw_ranks &lt;- rankSpatialCorGroups( visium_brain, spatCorObject = spat_cor_netw_DT, use_clus_name = &quot;spat_netw_clus&quot;) top_netw_spat_cluster &lt;- showSpatialCorFeats(spat_cor_netw_DT, use_clus_name = &quot;spat_netw_clus&quot;, selected_clusters = 6, show_top_feats = 1) Create metagene enrichment score for clusters cluster_genes_DT &lt;- showSpatialCorFeats(spat_cor_netw_DT, use_clus_name = &quot;spat_netw_clus&quot;, show_top_feats = 1) cluster_genes &lt;- cluster_genes_DT$clus names(cluster_genes) &lt;- cluster_genes_DT$feat_ID visium_brain &lt;- createMetafeats(visium_brain, feat_clusters = cluster_genes, name = &quot;cluster_metagene&quot;) spatCellPlot(visium_brain, spat_enr_names = &quot;cluster_metagene&quot;, cell_annotation_values = netw_ranks$clusters, point_size = 1, cow_n_col = 5) 7.5 Spatially informed clusters Get the top 30 genes per spatial co-expression cluster coexpr_dt &lt;- data.table::data.table( genes = names(spat_cor_netw_DT$cor_clusters$spat_netw_clus), cluster = spat_cor_netw_DT$cor_clusters$spat_netw_clus) data.table::setorder(coexpr_dt, cluster) top30_coexpr_dt &lt;- coexpr_dt[, head(.SD, 30) , by = cluster] spatial_genes &lt;- top30_coexpr_dt$genes Re-calculate the clustering visium_brain &lt;- runPCA(gobject = visium_brain, feats_to_use = spatial_genes, name = &quot;custom_pca&quot;) visium_brain &lt;- runUMAP(visium_brain, dim_reduction_name = &quot;custom_pca&quot;, dimensions_to_use = 1:20, name = &quot;custom_umap&quot;) visium_brain &lt;- createNearestNetwork(gobject = visium_brain, dim_reduction_name = &quot;custom_pca&quot;, dimensions_to_use = 1:20, k = 5, name = &quot;custom_NN&quot;) visium_brain &lt;- doLeidenCluster(gobject = visium_brain, network_name = &quot;custom_NN&quot;, resolution = 0.15, n_iterations = 1000, name = &quot;custom_leiden&quot;) Visualize spatPlot2D(visium_brain, cell_color = &quot;custom_leiden&quot;) plotUMAP(gobject = visium_brain, cell_color = &quot;custom_leiden&quot;, point_size = 1.5) 7.6 Spatial domains HMRF Hidden Markov Random Field (HMRF) models capture spatial dependencies and segment tissue regions based on shared gene expression patterns. Do HMRF with different betas on top 30 genes per spatial co-expression module HMRF_spatial_genes &lt;- doHMRF(gobject = visium_brain, expression_values = &quot;scaled&quot;, spatial_genes = spatial_genes, k = 20, spatial_network_name = &quot;spatial_network&quot;, betas = c(0, 10, 5), output_folder = &quot;11_HMRF/&quot;) visium_brain &lt;- addHMRF(gobject = visium_brain, HMRFoutput = HMRF_spatial_genes, k = 20, betas_to_add = c(0, 10, 20, 30, 40), hmrf_name = &quot;HMRF&quot;) spatPlot2D(gobject = visium_brain, cell_color = &quot;HMRF_k20_b.40&quot;) Visualize 7.7 Interactive tools Create a spatial plot brain_spatPlot &lt;- spatPlot2D(gobject = visium_brain, cell_color = &quot;leiden_clus&quot;, show_image = FALSE, return_plot = TRUE, point_size = 1) brain_spatPlot Run the Shiny app plotInteractivePolygons(brain_spatPlot) Select the regions of interest and save the coordinates polygon_coordinates &lt;- plotInteractivePolygons(brain_spatPlot) Transform the data.table or data.frame with coordinates into a Giotto polygon object giotto_polygons &lt;- createGiottoPolygonsFromDfr(polygon_coordinates, name = &quot;selections&quot;, calc_centroids = TRUE) Add the polygons (or spatial units) to the Giotto object visium_brain &lt;- addGiottoPolygons(gobject = visium_brain, gpolygons = list(giotto_polygons)) Add the corresponding polygon IDs to the cell metadata visium_brain &lt;- addPolygonCells(visium_brain, polygon_name = &quot;selections&quot;) Extract the coordinates and IDs from cells located within one or multiple regions of interest. getCellsFromPolygon(visium_brain, polygon_name = &quot;selections&quot;, polygons = &quot;polygon 1&quot;) If no polygon name is provided, the function will retrieve cells located within all polygons getCellsFromPolygon(visium_brain, polygon_name = &quot;selections&quot;) Compare the expression levels of some genes of interest between the selected regions comparePolygonExpression(visium_brain, selected_feats = c(&quot;Stmn1&quot;, &quot;Psd&quot;, &quot;Ly6h&quot;)) Calculate the top genes expressed within each region, then provide the result to compare polygons scran_results &lt;- findMarkers_one_vs_all(visium_brain, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, method = &quot;scran&quot;, expression_values = &quot;normalized&quot;, cluster_column = &quot;selections&quot;, min_feats = 2) top_genes &lt;- scran_results[, head(.SD, 2), by = &quot;cluster&quot;]$feats comparePolygonExpression(visium_brain, selected_feats = top_genes) Compare the abundance of cell types between the selected regions compareCellAbundance(visium_brain) Use other columns within the cell metadata table to compare the cell type abundances compareCellAbundance(visium_brain, cell_type_column = &quot;custom_leiden&quot;) Use the spatPlot arguments to isolate and plot each region. spatPlot2D(visium_brain, cell_color = &quot;leiden_clus&quot;, group_by = &quot;selections&quot;, cow_n_col = 3, point_size = 2, show_legend = FALSE) Color each cell by cluster, cell type or expression level. spatFeatPlot2D(visium_brain, expression_values = &quot;scaled&quot;, group_by = &quot;selections&quot;, feats = &quot;Psd&quot;, point_size = 2) Plot again the polygons plotPolygons(visium_brain, polygon_name = &quot;selections&quot;, x = brain_spatPlot) 7.8 Session info sessionInfo() "],["visium-hd.html", "8 Visium HD 8.1 Objective 8.2 Background 8.3 Data Ingestion 8.4 Tiling and aggregation 8.5 Scalability and projection functions 8.6 Spatial expression patterns 8.7 Spatial co-expression modules", " 8 Visium HD Edward C. Ruiz August 6th 2024 8.1 Objective This tutorial demonstrates how to process Visium HD data at the highest 2 micron bin resolution using Giotto Suite and methods from the [dbverse] (link). 8.2 Background 8.2.1 Visium HD Technology Figure 8.1: Overview of Visium HD. Source: 10X Genomics Visium HD is a spatial transcriptomics technology recently developed by 10X Genomics. Details about this platform are discussed on the official 10X Genomics Visium HD website and the preprint by Oliveira et al. 2024 on bioRxiv. At the highest resolution, Visium HD data contains a 2 micron bin size. At the lowest resolution, Visium HD data is binned at a 16 micron bin size after running the spaceranger pipeline. 8.2.2 Colorectal Cancer Sample Figure 8.2: Colorectal Cancer Overview. Source: 10X Genomics For this tutorial we will be using the publicly available Colorectal Cancer Visium HD dataset. Details about this dataset and a link to download the raw data can be found at the 10X Genomics website. 8.3 Data Ingestion 8.3.1 Visium HD output data format Figure 8.3: File structure of Visium HD data processed with spaceranger pipeline. Visium HD data processed with the spaceranger pipeline is organized in this format containing various files associated with the sample. The files highlighted in yellow are what we will be using to read in these datasets. 8.3.2 Read in raw data # get10Xmatrix() # GiottoData:: 8.3.3 Giotto Visium HD convenience function We have also developed a convenience function to read in Visium HD data directly into Giotto. This function will read in the data and create a Giotto Object. # importVisiumHD() 8.4 Tiling and aggregation The Visium HD data is organized in a grid format. We can aggregate the data into larger bins to reduce the dimensionality of the data. Giotto Suite provides options to bin data not only with squares, but also through hexagons and triangles. Here we use a hexagon tesselation to aggregate the data into arbitrary cells. # tessellate() 8.5 Scalability and projection functions filter and normalization workflow PCA projection 8.6 Spatial expression patterns plotting 8.7 Spatial co-expression modules binspect? "],["xenium.html", "9 Xenium 9.1 Introduction to spatial dataset 9.2 Additional package requirements 9.3 Introduce mini object 9.4 Read in raw data 9.5 Overlap txs &amp; polygons 9.6 Transcript enrichment GSEA 9.7 Spatial location analysis 9.8 Visualizations", " 9 Xenium Jiaji George Chen August 6th 2024 9.1 Introduction to spatial dataset This is the 10X Xenium FFPE Human Lung Cancer dataset. Xenium captures individual transcript detections with a spatial resolution of 100s of nanometers, providing an extremely highly resolved subcellular spatial dataset. This particular dataset also showcases their newly released multimodal cell segmentation outputs. The Xenium Human Multi-Tissue and Cancer Panel (377) genes was used. The exported data is from their Xenium Onboard Analysis v2.0.0 pipeline. The full data for this example can be found here: here Input Files are additional files that are not part of the output bundles, usually some raw files the pipeline uses or extra info. Output Files are the directories that are exported by the Xenium pipeline that can be expected from every run. 9.2 Additional package requirements When working with this data, some additional packages must be downloaded. - arrow is needed - requires ZTSD codec to open these parquets. 9.3 Introduce mini object save_dir &lt;- &quot;~/Documents/GitHub/giotto_workshop_2024/img/02_session3&quot; 9.4 Read in raw data Transcript coordinates Polygon coordinates Visualizations affine mapping? 9.5 Overlap txs &amp; polygons Typical aggregated workflow Feature/molecule specific analysis Visualizations 9.6 Transcript enrichment GSEA text 9.7 Spatial location analysis Spatial cell type co-localization analysis Spatial niche analysis Spatial niche trajectory analysis 9.8 Visualizations zarr_exp &lt;- “https://scc-ondemand1.bu.edu/pun/sys/dashboard/files/fs//projectnb/rd-spat/DATA/Public_data/Spatial/Multiplexing_RNA/xenium/v2.0_pipeline/FFPE_LungCancer/cell_features” datadir &lt;- “/projectnb2/rd-spat/DATA/Public_data/Spatial/Multiplexing_RNA/xenium/v2.0_pipeline/FFPE_LungCancer/” manifest &lt;- list.files( datadir, full.names = TRUE, ) |&gt; as.list() names(manifest) &lt;- list.files(datadir) force(names(manifest)) tx_path &lt;- manifest\\(transcripts.csv.gz poly_cell_path &lt;- manifest\\)cell_boundaries.csv.gz poly_nuc_path &lt;- manifest$nucleus_boundaries.csv.gz image_path &lt;- manifest\\(Xenium_V1_humanLung_Cancer_FFPE_he_image.ome.tif aff_path &lt;- manifest\\)Xenium_V1_humanLung_Cancer_FFPE_he_imagealignment.csv cell &lt;- manifest$cells.csv.gz "],["exploration.html", "10 —– exploration", " 10 —– exploration "],["image.html", "11 IMAGE", " 11 IMAGE aff &lt;- data.table::fread(aff_path) reticulate::source_python(file = “/projectnb/rd-spat/HOME/george/scripts/tifffile_convert.py”) GiottoUtils::package_check(“os”, repository = “pip:os”) GiottoUtils::package_check(“multiprocessing”, repository = “pip:multiprocessing”) GiottoUtils::package_check(“tifffile”, repository = “pip:tifffile”) out_tif &lt;- “/projectnb/rd-spat/HOME/george/tmp/tifffile_testing/test.tif” "],["ometif_2_tifimage_path-output_file-out_tif-chunk_rows-chunk_rows-overwrite-true.html", "12 ometif_2_tif(image_path, output_file = out_tif, chunk_rows = chunk_rows, overwrite = TRUE)", " 12 ometif_2_tif(image_path, output_file = out_tif, chunk_rows = chunk_rows, overwrite = TRUE) ometif_2_tif(image_path, output_file = out_tif, overwrite = TRUE) test &lt;- createGiottoLargeImage(out_tif) n_before &lt;- .nr(tx_arrow) tx_arrow &lt;- dplyr::filter(tx_arrow, qv &gt; qv_threshold) n_after &lt;- .nr(tx_arrow) out_if_fmt &lt;- “/projectnb/rd-spat/HOME/george/tmp/tifffile_testing/if%d.tif” source_if_fmt &lt;- “/projectnb2/rd-spat/DATA/Public_data/Spatial/Multiplexing_RNA/xenium/v2.0_pipeline/FFPE_LungCancer//morphology_focus/morphology_focus_000%d.ome.tif” ometif_2_tif(sprintf(source_if_fmt, 0), output_file = sprintf(out_if_fmt, 0), overwrite = TRUE) ometif_2_tif(sprintf(source_if_fmt, 1), output_file = sprintf(out_if_fmt, 1), overwrite = TRUE) ometif_2_tif(sprintf(source_if_fmt, 2), output_file = sprintf(out_if_fmt, 2), overwrite = TRUE) ometif_2_tif(sprintf(source_if_fmt, 3), output_file = sprintf(out_if_fmt, 3), overwrite = TRUE) img_if_list &lt;- lapply( sprintf(out_if_fmt, 0:3), createGiottoLargeImage ) "],["example-usage.html", "13 # Example usage", " 13 # Example usage "],["input_file-pathtoinputfile.ome.html", "14 input_file = “path/to/input/file.ome.tif”", " 14 input_file = “path/to/input/file.ome.tif” "],["output_file-pathtooutputfile.html", "15 output_file = “path/to/output/file.tif”", " 15 output_file = “path/to/output/file.tif” "],["chunk_size-1000-1000-adjust-the-chunk-size-as-needed.html", "16 chunk_size = (1000, 1000) # Adjust the chunk size as needed", " 16 chunk_size = (1000, 1000) # Adjust the chunk size as needed "],["num_processes-4-adjust-the-number-of-processes-based-on-available-cpu-cores.html", "17 num_processes = 4 # Adjust the number of processes based on available CPU cores", " 17 num_processes = 4 # Adjust the number of processes based on available CPU cores "],["section.html", "18 ", " 18 "],["ometif_2_tifinput_file-output_file-chunk_size-num_processes.html", "19 ometif_2_tif(input_file, output_file, chunk_size, num_processes)", " 19 ometif_2_tif(input_file, output_file, chunk_size, num_processes) "],["transcripts.html", "20 TRANSCRIPTS", " 20 TRANSCRIPTS tx &lt;- data.table::fread(tx_path, colClasses = c(transcript_id = “character”)) poly_cell_dt &lt;- data.table::fread(poly_cell_path) poly_nuc_dt &lt;- data.table::fread(poly_nuc_path) gpoints_list &lt;- GiottoClass::createGiottoPoints( tx, x_colname = “x_location”, y_colname = “y_location”, feat_ID_colname = “feature_name”, feat_type = c(“rna”, “NegControlProbe”, “UnassignedCodeword”, “NegControlCodeword”), split_keyword = list(“NegControlProbe”, “UnassignedCodeword”, “NegControlCodeword”) ) gp_filter &lt;- gpoints_list\\(rna[gpoints_list\\)rna$qv &gt;= 20] "],["where-are-the-issue-tx-at.html", "21 where are the issue TX at?", " 21 where are the issue TX at? plot(gp_filter@spatVector, values = gp_filter$qv, type = “continuous”, cex = 0.1, col = GiottoVisuals::getColors(“magma”)) library(ggplot2) type_qv &lt;- data.table::rbindlist( list( data.table::data.table(type = “genes”, qv = gpoints_list\\(rna\\)qv), data.table::data.table(type = “NegControlProbe”, qv = gpoints_list\\(NegControlProbe\\)qv), data.table::data.table(type = “UnassignedCodeword”, qv = gpoints_list\\(UnassignedCodeword\\)qv), data.table::data.table(type = “NegControlCodeword”, qv = gpoints_list\\(NegControlCodeword\\)qv) ) ) ggplot(data = type_qv, aes(x = type, y = qv, fill = type)) + geom_violin() "],["polys.html", "22 POLYS", " 22 POLYS gpoly_cell &lt;- createGiottoPolygon(poly_cell_dt, name = “cell”) gpoly_nuc &lt;- createGiottoPolygon(poly_nuc_dt, name = “nucleus”) mini_ext &lt;- ext(6500,7500, 1300, 2000) plot(gpoly_cell, col = “magenta”, ext = mini_ext, background = “black”) plot(gpoly_nuc, add = T, col = “cyan”, ext = mini_ext) plot(gp_filter, add = T, col = “yellow”, alpha = 0.3, ext = mini_ext, raster = F) "],["giotto.html", "23 giotto", " 23 giotto g &lt;- giotto() g &lt;- setGiotto(g, gp_filter) g &lt;- setGiotto(g, gpoly_cell) g &lt;- setGiotto(g, gpoly_nuc) g &lt;- calculateOverlap( g, feat_info = “rna”, spatial_info = “cell”, return_gobject = T ) g &lt;- overlapToMatrix( g, poly_info = “cell”, feat_info = “rna”, return_gobject = TRUE ) savedir &lt;- “/projectnb2/rd-spat/HOME/george/projects/xenium_processing/lung_test/” instructions(g, “save_dir”) &lt;- savedir instructions(g, “save_plot”) &lt;- TRUE instructions(g, “return_plot”) &lt;- FALSE instructions(g, “show_plot”) &lt;- FALSE g &lt;- addStatistics(g, expression_values = “raw”) spatPlot2D(g, cell_color = “total_expr”, color_as_factor = FALSE, point_shape = “no_border”, point_size = 0.1, gradient_style = “s”, background_color = “black”, save_param = list( base_width = 15, base_height = 6 )) hist(pDataDT(g)$nr_feats) filterCombinations( g, feat_det_in_min_cells = c(100, 200, 200), min_det_feats_per_cell = c(10, 20, 30), expression_thresholds = 1 ) g &lt;- filterGiotto( g, feat_det_in_min_cells = 100, min_det_feats_per_cell = 10, expression_threshold = 1 ) g &lt;- normalizeGiotto(g) "],["no-hvf-calc-since-there-are-not-that-many-different-gene-species.html", "24 no HVF calc since there are not that many different gene species", " 24 no HVF calc since there are not that many different gene species g &lt;- runPCA(gobject = g, spat_unit = ‘cell’, expression_values = ‘scaled’, feats_to_use = NULL, scale_unit = F, center = F) screePlot(g, ncp = 20) my_colors &lt;- c(“#6D0C00”, “magenta”, “#FFBBCE”, “#FFDDDF”, “#FFEEEE”, “#FFFEFE”, “white”, “white”) plotPCA(g, cell_color = “total_expr”, color_as_factor = FALSE, cell_color_gradient = my_colors, point_shape = “no_border”, gradient_style = “s”, background = “black”, point_size = 0.1, save_param = list( save_name = “pca_expr” ) ) g &lt;- runUMAPprojection( g, dimensions_to_use = 1:15, random_subset = 10000 ) dimPlot2D( g, dim_reduction_name = “umap.projection”, dim_reduction_to_use = “umap”, cell_color = “total_expr”, cell_color_gradient = my_colors, color_as_factor = FALSE, point_shape = “no_border”, gradient_style = “s”, background = “black”, point_size = 0.1, save_param = list( save_name = “umap.projection_expr” ) ) g &lt;- createNearestNetwork(g) "],["set-seed-for-reproducibility.html", "25 set seed for reproducibility", " 25 set seed for reproducibility set.seed(123) g_mini &lt;- subsetGiotto(g, cell_ids = sample(spatIDs(g), size = 10000)) g_mini &lt;- createNearestNetwork(g_mini) g_mini &lt;- doLeidenCluster(g_mini, resolution = 1.4) "],["dimplot2d.html", "26 dimPlot2D(", " 26 dimPlot2D( "],["g_mini.html", "27 g_mini,", " 27 g_mini, "],["spat_unit-cell.html", "28 spat_unit = “cell”,", " 28 spat_unit = “cell”, "],["feat_type-rna.html", "29 feat_type = “rna”,", " 29 feat_type = “rna”, "],["cell_color-leiden_clus.html", "30 cell_color = “leiden_clus”,", " 30 cell_color = “leiden_clus”, "],["dim_reduction_name-umap.html", "31 dim_reduction_name = “umap.projection”,", " 31 dim_reduction_name = “umap.projection”, "],["dim_reduction_to_use-umap.html", "32 dim_reduction_to_use = “umap”,", " 32 dim_reduction_to_use = “umap”, "],["save_param-list.html", "33 save_param = list(", " 33 save_param = list( "],["save_name-mini_umap_1.html", "34 save_name = “mini_umap_1.2”", " 34 save_name = “mini_umap_1.2” "],["section-1.html", "35 )", " 35 ) "],["section-2.html", "36 )", " 36 ) clus_color &lt;- getColors(“Vivid”, n = 17)[] clus_color[9] &lt;- “lightgrey” clus_color[5] &lt;- “yellow” clus_color[3] &lt;- “#00AAFF” clus_color[6] &lt;- “darkgreen” clus_color &lt;- clus_color[c(2, 5, 1, 7, 6, 3, 4, 9, 8, 10, 12, 11, 14, 13, 15, 16, 17)] clus_color &lt;- c(“#00AAFF”, “#E58606”, “#B763A7”, “#437478”, “#87727B”, “darkgreen”, “#56BC9D”, “#5668AF”, “yellow”, “#B99F3A”, “#E5625E”, “#448DAE”, “#A5AA99”, “#D8497A”, “#93538D”, “#BF5C91”, “lightgrey”) dimPlot2D( g_mini, spat_unit = “cell”, feat_type = “rna”, cell_color = “leiden_clus”, cell_color_code = clus_color, dim_reduction_name = “umap.projection”, dim_reduction_to_use = “umap”, save_param = list( save_name = “mini_umap_1.4” ) ) "],["seems-like-a-good-res.html", "37 1.4 seems like a good res", " 37 1.4 seems like a good res "],["project-values-back-via-knn-classifier-fnnknn.html", "38 project values back via kNN classifier (FNN::knn)", " 38 project values back via kNN classifier (FNN::knn) g &lt;- doClusterProjection( target_gobject = g, target_cluster_label_name = “leiden_clus”, source_gobject = g_mini, # res 1.4 source_cluster_labels = “leiden_clus” ) dimPlot2D(g, cell_color = “leiden_clus”, cell_color_code = clus_color[c(1, 10:17, 2:9)], dim_reduction_to_use = “umap”, dim_reduction_name = “umap.projection”, save_param = list( save_name = “umap.project_1.4” )) cellmeta &lt;- pDataDT(g) cellmeta[, major_clus := leiden_clus] cellmeta[major_clus %in% c(1, 7, 6, 8, 3, 5), major_clus := “combined_1”] m_clus &lt;- cellmeta[, c(“cell_ID”, “major_clus”)] g &lt;- addCellMetadata(g, new_metadata = m_clus, by_column = T) spatPlot2D(g, cell_color = “leiden_clus”, point_size = 0.1, point_shape = “no_border”, cell_color_code = clus_color[c(1, 10:17, 2:9)], background = “black”, save_param = list( base_width = 15, base_height = 6, save_name = “spat_leiden” )) "],["spatplot2dg-cell_color-major_clus.html", "39 spatPlot2D(g, cell_color = “major_clus”,", " 39 spatPlot2D(g, cell_color = “major_clus”, "],["point_size-0.html", "40 point_size = 0.1,", " 40 point_size = 0.1, "],["point_shape-no_border.html", "41 point_shape = “no_border”,", " 41 point_shape = “no_border”, "],["cell_color_code-clus_colorc1-1017-29c1359-14-17-11.html", "42 cell_color_code = clus_color[c(1, 10:17, 2:9)][c(1:3,5:9, 14, 17, 11)],", " 42 cell_color_code = clus_color[c(1, 10:17, 2:9)][c(1:3,5:9, 14, 17, 11)], "],["background-black.html", "43 background = “black”,", " 43 background = “black”, "],["save_param-list-1.html", "44 save_param = list(", " 44 save_param = list( "],["base_width-15.html", "45 base_width = 15,", " 45 base_width = 15, "],["base_height-6.html", "46 base_height = 6,", " 46 base_height = 6, "],["save_name-spat_major.html", "47 save_name = “spat_major”", " 47 save_name = “spat_major” "],["section-3.html", "48 ))", " 48 )) spatFeatPlot2D(g, feats = c(“MKI67”, “CD3E”, “CD4”, “CD8A”, “CD19”, “CD79A”), point_size = 0.1, point_shape = “no_border”, background = “black”, cow_n_col = 1L, gradient_style = “s”, save_param = list( base_width = 15, base_height = 30 )) spatFeatPlot2D(g, feats = c(“CD68”, “CD27”, “SFTA2”, “KRT7”, “SERPINB3”, “SOX2”, “SMOC”), point_size = 0.1, point_shape = “no_border”, background = “black”, cow_n_col = 1L, gradient_style = “s”, save_param = list( base_width = 15, base_height = 30 )) "],["niches.html", "49 niches", " 49 niches g = createSpatialNetwork( gobject = g, spat_unit = ‘cell’, method = ‘Delaunay’ ) g = calculateSpatCellMetadataProportions( gobject = g, spat_unit = ‘cell’, feat_type = ‘rna’, spat_network = ‘Delaunay_network’, metadata_column = ‘leiden_clus’, name = ‘proportion’ ) "],["visualize-niche-level-enrichment-for-leiden-cluster-3-in-spat_unit-cell.html", "50 visualize niche-level enrichment for leiden cluster 3 in spat_unit “cell”", " 50 visualize niche-level enrichment for leiden cluster 3 in spat_unit “cell” spatPlot2D( gobject = g, spat_unit = ‘cell’, point_size = 0.1, spat_enr_names = ‘proportion’, color_as_factor = FALSE, gradient_style = ‘sequential’, cell_color = ‘3’, point_shape = “no_border”, save_param = list( save_name = “niche_3”, base_width = 15, base_height = 6 ) ) prop_table = getSpatialEnrichment( g, spat_unit = ‘cell’, name = ‘proportion’, output = ‘data.table’ ) # convert the data.table to a sparse Matrix with row and colnames # here we use a utility function to perform the operation prop_matrix = GiottoUtils::dt_to_matrix(prop_table) "],["these-enrichments-are-essentially-a-measure-of-how-many-cells-of-each.html", "51 These enrichments are essentially a measure of how many cells of each", " 51 These enrichments are essentially a measure of how many cells of each "],["leiden-cluster-exist-in-the-local-region.html", "52 leiden cluster exist in the local region", " 52 leiden cluster exist in the local region "],["section-4.html", "53 ", " 53 "],["using-kmeans-we-can-classify-each-cell-by-its-niche-leiden-cluster-proportions.html", "54 Using kmeans, we can classify each cell by its niche leiden cluster proportions", " 54 Using kmeans, we can classify each cell by its niche leiden cluster proportions set.seed(12345) # set seed for kmeans prop_kmeans = kmeans(x = prop_matrix, centers = 6, iter.max = 100, nstart = 3) prop_kmeansDT = data.table::data.table( cell_ID = names(prop_kmeans\\(cluster), niche = prop_kmeans\\)cluster ) "],["add-kmeans-clustering-of-niches-to-cell-metadata.html", "55 add kmeans clustering of niches to cell metadata", " 55 add kmeans clustering of niches to cell metadata g = addCellMetadata( g, spat_unit = ‘cell’ , new_metadata = prop_kmeansDT, by_column = TRUE, column_cell_ID = ‘cell_ID’ ) "],["spatially-visualize-the-niches.html", "56 Spatially visualize the niches", " 56 Spatially visualize the niches spatPlot(gobject = g, show_network = TRUE, network_color = ‘lightgray’, spatial_network_name = ‘Delaunay_network’, cell_color = ‘niche’, point_size = 0.1, point_shape = “no_border”, save_param = list( save_name = “niches”, base_width = 15, base_height = 6 )) "],["gene-enrichment.html", "57 Gene enrichment", " 57 Gene enrichment scran_markers &lt;- findScranMarkers_one_vs_all( g, cluster_column = “leiden_clus”, expression_values = “normalized” ) topgenes_scran = scran_markers[, head(.SD, 2), by = ‘cluster’]$feats "],["violinplot.html", "58 violinplot", " 58 violinplot violinPlot(g, feats = unique(topgenes_scran), cluster_column = ‘leiden_clus’, strip_text = 10, strip_position = ‘right’, save_param = list(base_width = 5)) "],["spatial-proteomics-multiplex-if.html", "59 Spatial proteomics: multiplex IF 59.1 Read in raw data 59.2 Overlap intensity &amp; workflows", " 59 Spatial proteomics: multiplex IF Junxiang Xu August 6th 2024 59.1 Read in raw data Intensity data (IF or any other image) Polygon coordinates Visualizations 59.2 Overlap intensity &amp; workflows Typical aggregated workflow Visualizations "],["working-with-multiple-samples.html", "60 Working with multiple samples 60.1 Create individual giotto objects 60.2 Join Giotto Objects 60.3 Perform Harmony and default workflows 60.4 Visualizations", " 60 Working with multiple samples Jeff Sheridan August 7th 2024 60.1 Create individual giotto objects 60.2 Join Giotto Objects 60.3 Perform Harmony and default workflows 60.4 Visualizations "],["spatial-multi-modal-analysis.html", "61 Spatial multi-modal analysis 61.1 Spatial transforms", " 61 Spatial multi-modal analysis Junxiang Xu August 7th 2024 61.1 Spatial transforms Spatial transformations of data will become more and more important in the near future due to the fact that performing spatial analyses across any two sections of tissue from the same block will require that data to be spatially aligned into a common coordinate space. Minute differences during the sectioning process from the cutting motion to how long an FFPE section was floated can result in even neighboring sections being distorted when compared side-by-side. These differences make it difficult to assemble multislice and/or cross platform multimodal datasets into a cohesive 3D volume. The solution for this is to perform registration across either the dataset images or expression information. Based on the registration results, both the raster images and vector feature and polygon information can be aligned into a continuous whole. Ideally this registration will be a free deformation based on sets of control points or a deformation matrix, however affine transforms already provide a good approximation. In either case, the transform or deformation applied must work in the same way across both raster and vector information. Giotto provides spatial classes and methods for easy manipulation of data with 2D affine transformations. These functionalities are all available from GiottoClass. 61.1.1 Spatial transforms: We support simple transformations and more complex affine transformations which can be used to combine and encode more than one simple transform. spatShift() - translations spin() - rotations (degrees) rescale() - scaling flip() - flip vertical or horizontal across arbitrary lines t() - transpose shear() - shear transform affine() - affine transform 61.1.2 Spatial utilities: Helpful functions for use alongside these spatial transforms are ext() for finding the spatial bounding box of where your data object is, crop() for cutting out a spatial region of the data, and plot() for terra/base plots of the data. ext() - spatial extent or bounding box crop() - cut out a spatial region of the data plot() - plot a spatial object 61.1.3 Spatial classes: Giotto’s spatial subobjects respond to the above functions. The Giotto object itself can also be affine transformed. spatLocsObj - xy centroids spatialNetworkObj - spatial networks between centroids giottoPoints - xy feature point detections giottoPolygon - spatial polygons giottoImage (mostly deprecated) - magick-based images giottoLargeImage/giottoAffineImage - terra-based images affine2d - affine matrix container giotto - giotto analysis object # load in data library(Giotto) g &lt;- GiottoData::loadGiottoMini(&quot;vizgen&quot;) activeSpatUnit(g) &lt;- &quot;aggregate&quot; gpoly &lt;- getPolygonInfo(g, return_giottoPolygon = TRUE) gimg &lt;- getGiottoImage(g) # examples of the simple transforms using giottoPolygon p &lt;- par(no.readonly = TRUE) par(mfrow=c(2,4)) plot(gpoly) gpoly |&gt; spatShift(dx = 1000) |&gt; plot(main = &quot;spatShift()&quot;) gpoly |&gt; spin(45) |&gt; plot(main = &quot;spin()&quot;) gpoly |&gt; rescale(10) |&gt; plot(main = &quot;rescale()&quot;) gpoly |&gt; flip(direction = &quot;vertical&quot;) |&gt; plot(main = &quot;flip()&quot;) gpoly |&gt; t() |&gt; plot(main = &quot;t()&quot;) gpoly |&gt; shear(fx = 0.5) |&gt; plot(main = &quot;shear()&quot;) par(p) Giotto also provides a utility affine2d class that can be created from any affine matrix. The affine2d can then be used to accumulate simple transforms that can be applied to spatial objects in a single step using affine() # create affine2d aff &lt;- affine(diag(c(1,1))) aff &lt;- aff |&gt; spatShift(dx = 1000) |&gt; spin(45) |&gt; rescale(10) |&gt; flip(direction = &quot;vertical&quot;) |&gt; t() |&gt; shear(fx = 0.5) force(aff) &lt;affine2d&gt; anchor : -180, 180, -90, 90 (xmin, xmax, ymin, ymax) rotate : -0.785398163397448 (rad) shear : 0.5, 0 (x, y) scale : 10, 10 (x, y) translate : 3.43401245619535e-13, 1000 (x, y) gpoly |&gt; affine(aff) |&gt; plot(main = &quot;affine()&quot;) "],["image-transforms.html", "62 Image transforms 62.1 Co-registration of datasets 62.2 Examples in giotto suite manuscript", " 62 Image transforms Giotto uses giottoLargeImages as the core image class which is based on terra SpatRaster. Images are not loaded into memory when the object is generated and instead an amount of regular sampling appropriate to the zoom level requested is performed at time of plotting. spatShift() and rescale() operations are supported by terra SpatRaster, and we inherit those functionalities. spin(), flip(), t(), shear(), affine() operations will coerce giottoLargeImage to giottoAffineImage, which is much the same, except it contains an affine2d object that tracks spatial manipulations performed, so that they can be applied through magick::image_distort() processing after sampled values are pulled into memory. giottoAffineImage also has alternative ext() and crop() methods so that those operations respect both the expected post-affine space and untransformed source image. # affine transform of image info matches with polygon info gimg |&gt; affine(aff) |&gt; plot() gpoly |&gt; affine(aff) |&gt; plot(add = TRUE, border = &quot;cyan&quot;, lwd = 0.3) # affine of the giotto object g |&gt; affine(aff) |&gt; spatInSituPlotPoints( show_image = TRUE, feats = list(rna = c(&quot;Adgrl1&quot;, &quot;Gfap&quot;, &quot;Ntrk3&quot;, &quot;Slc17a7&quot;)), feats_color_code = rainbow(4), polygon_color = &quot;cyan&quot;, polygon_line_size = 0.1, point_size = 0.1, use_overlap = FALSE ) Currently giotto image objects are not fully compatible with .ome.tif files. terra which relies on gdal drivers for image loading will find that the Gtiff driver opens some .ome.tif images, but fails when certain compressions (notably JP2000 as used by 10x for their single-channel stains) are used. 62.1 Co-registration of datasets text 62.2 Examples in giotto suite manuscript text sessionInfo() "],["multi-omics-integration.html", "63 Multi-omics integration 63.1 Introduction to the spatial dataset 63.2 Download dataset 63.3 Create the Giotto object 63.4 Subset on spots that were covered by tissue 63.5 RNA processing 63.6 Protein processing 63.7 Multi-omics integration 63.8 Session info", " 63 Multi-omics integration Joselyn Cristina Chávez Fuentes August 7th 2024 63.1 Introduction to the spatial dataset The Human glioblastoma (FFPE) dataset was obtained from 10X Genomics. The tissue was sectioned as described in visium_glioblastoma CytAssist Spatial Gene Expression for FFPE – Tissue Preparation Guide Demonstrated Protocol (CG000518). 5 µm tissue sections were placed on Superfrost glass slides, then IF stained following deparaffinization, then hard coverslipped. Sections were imaged, decoverslipped, followed by Demonstrated Protocol (CG000494). More information about this dataset can be found here. 63.2 Download dataset You need to download the expression matrix and spatial information by running these commands: dir.create(&quot;data&quot;) download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/2.1.0/CytAssist_FFPE_Protein_Expression_Human_Glioblastoma/CytAssist_FFPE_Protein_Expression_Human_Glioblastoma_raw_feature_bc_matrix.tar.gz&quot;, destfile = &quot;data/CytAssist_FFPE_Protein_Expression_Human_Glioblastoma_raw_feature_bc_matrix.tar.gz&quot;) download.file(url = &quot;https://cf.10xgenomics.com/samples/spatial-exp/2.1.0/CytAssist_FFPE_Protein_Expression_Human_Glioblastoma/CytAssist_FFPE_Protein_Expression_Human_Glioblastoma_spatial.tar.gz&quot;, destfile = &quot;data/CytAssist_FFPE_Protein_Expression_Human_Glioblastoma_spatial.tar.gz&quot;) After downloading, unzip the gz files. You should get the “raw_feature_bc_matrix” and “spatial” folders inside “data/”. 63.3 Create the Giotto object The minimum requirements are: matrix with expression information (or the path to) x,y(,z) coordinates for cells or spots (or the path to) createGiottoVisiumObject() will automatically detect both RNA and Protein modalities in the expression matrix and will create a multi-omics Giotto object. library(Giotto) ## Set instructions results_folder &lt;- &quot;results/&quot; python_path &lt;- NULL instructions &lt;- createGiottoInstructions( save_dir = results_folder, save_plot = TRUE, show_plot = FALSE, return_plot = FALSE, python_path = python_path ) # Provide the path to the visium_glioblastoma folder data_path &lt;- &quot;data&quot; # Create object directly from the visium_glioblastoma folder visium_glioblastoma &lt;- createGiottoVisiumObject( visium_dir = data_path, expr_data = &quot;raw&quot;, png_name = &quot;tissue_lowres_image.png&quot;, gene_column_index = 2, instructions = instructions ) Print the information of the object, note that both rna and protein are listed in the expression slot visium_glioblastoma 63.4 Subset on spots that were covered by tissue spatPlot2D( gobject = visium_glioblastoma, cell_color = &quot;in_tissue&quot;, point_size = 2, cell_color_code = c(&quot;0&quot; = &quot;lightgrey&quot;, &quot;1&quot; = &quot;blue&quot;), show_image = TRUE, image_name = &quot;image&quot; ) metadata &lt;- getCellMetadata(gobject = visium_glioblastoma, output = &quot;data.table&quot;) in_tissue_barcodes &lt;- metadata[in_tissue == 1]$cell_ID visium_glioblastoma &lt;- subsetGiotto(visium_glioblastoma, cell_ids = in_tissue_barcodes) 63.5 RNA processing Filtering, normalization, and statistics visium_glioblastoma &lt;- filterGiotto( gobject = visium_glioblastoma, expression_threshold = 1, feat_det_in_min_cells = 50, min_det_feats_per_cell = 1000, expression_values = &quot;raw&quot;, verbose = TRUE) visium_glioblastoma &lt;- normalizeGiotto(gobject = visium_glioblastoma, scalefactor = 6000, verbose = TRUE) visium_glioblastoma &lt;- addStatistics(gobject = visium_glioblastoma) Dimension reduction visium_glioblastoma &lt;- calculateHVF(gobject = visium_glioblastoma) visium_glioblastoma &lt;- runPCA(gobject = visium_glioblastoma) Clustering visium_glioblastoma &lt;- runUMAP(visium_glioblastoma, dimensions_to_use = 1:10) visium_glioblastoma &lt;- createNearestNetwork(gobject = visium_glioblastoma, dimensions_to_use = 1:10, k = 30) visium_glioblastoma &lt;- doLeidenCluster(gobject = visium_glioblastoma, resolution = 1, n_iterations = 1000) Visualization plotUMAP(gobject = visium_glioblastoma, cell_color = &quot;leiden_clus&quot;, show_NN_network = TRUE, point_size = 2) spatPlot2D(gobject = visium_glioblastoma, show_image = FALSE, cell_color = &quot;leiden_clus&quot;, point_size = 2) 63.6 Protein processing Filtering, normalization, and statistics visium_glioblastoma &lt;- filterGiotto(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, expression_threshold = 1, feat_det_in_min_cells = 50, min_det_feats_per_cell = 1, expression_values = &quot;raw&quot;, verbose = TRUE) visium_glioblastoma &lt;- normalizeGiotto(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, scalefactor = 6000, verbose = TRUE) visium_glioblastoma &lt;- addStatistics(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;) Dimension reduction visium_glioblastoma &lt;- runPCA(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;) Clustering visium_glioblastoma &lt;- runUMAP(visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, dimensions_to_use = 1:10) visium_glioblastoma &lt;- createNearestNetwork(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, dimensions_to_use = 1:10, k = 30) visium_glioblastoma &lt;- doLeidenCluster(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, resolution = 1, n_iterations = 1000) Visualization plotUMAP(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, cell_color = &quot;leiden_clus&quot;, show_NN_network = TRUE, point_size = 2) spatPlot2D(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, show_image = FALSE, cell_color = &quot;leiden_clus&quot;, point_size = 2) 63.7 Multi-omics integration Calculate kNN ## RNA modality visium_glioblastoma &lt;- createNearestNetwork(gobject = visium_glioblastoma, type = &quot;kNN&quot;, dimensions_to_use = 1:10, k = 20) ## Protein modality visium_glioblastoma &lt;- createNearestNetwork(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;protein&quot;, type = &quot;kNN&quot;, dimensions_to_use = 1:10, k = 20) Run WNN visium_glioblastoma &lt;- runWNN(visium_glioblastoma, spat_unit = &quot;cell&quot;, modality_1 = &quot;rna&quot;, modality_2 = &quot;protein&quot;, pca_name_modality_1 = &quot;pca&quot;, pca_name_modality_2 = &quot;protein.pca&quot;, k = 20, integrated_feat_type = NULL, matrix_result_name = NULL, w_name_modality_1 = NULL, w_name_modality_2 = NULL, verbose = TRUE) Run Integrated umap visium_glioblastoma &lt;- runIntegratedUMAP(visium_glioblastoma, modality1 = &quot;rna&quot;, modality2 = &quot;protein&quot;, spread = 5, min_dist = 0.5, force = FALSE) Calculate integrated clusters visium_glioblastoma &lt;- doLeidenCluster(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, nn_network_to_use = &quot;kNN&quot;, network_name = &quot;integrated_kNN&quot;, name = &quot;integrated_leiden_clus&quot;, resolution = 1) Visualize the integrated umap plotUMAP(gobject = visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, cell_color = &quot;integrated_leiden_clus&quot;, dim_reduction_name = &quot;integrated.umap&quot;, point_size = 1.5, title = &quot;Integrated UMAP using Integrated Leiden clusters&quot;, axis_title = 12, axis_text = 10 ) Visualize spatial plot with integrated clusters spatPlot2D(visium_glioblastoma, spat_unit = &quot;cell&quot;, feat_type = &quot;rna&quot;, cell_color = &quot;integrated_leiden_clus&quot;, point_size = 2, show_image = FALSE, title = &quot;Integrated Leiden clustering&quot;) 63.8 Session info sessionInfo() R version 4.4.1 (2024-06-14) Platform: aarch64-apple-darwin20 Running under: macOS Sonoma 14.5 Matrix products: default BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib; LAPACK version 3.12.0 locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 time zone: America/New_York tzcode source: internal attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] Giotto_4.0.8 GiottoClass_0.3.1 loaded via a namespace (and not attached): [1] colorRamp2_0.1.0 deldir_2.0-4 rlang_1.1.4 [4] magrittr_2.0.3 RcppAnnoy_0.0.22 GiottoUtils_0.1.8 [7] matrixStats_1.3.0 compiler_4.4.1 png_0.1-8 [10] systemfonts_1.1.0 vctrs_0.6.5 reshape2_1.4.4 [13] stringr_1.5.1 pkgconfig_2.0.3 crayon_1.5.3 [16] fastmap_1.2.0 backports_1.5.0 magick_2.8.4 [19] XVector_0.44.0 labeling_0.4.3 utf8_1.2.4 [22] rmarkdown_2.27 ragg_1.3.2 purrr_1.0.2 [25] xfun_0.46 zlibbioc_1.50.0 beachmat_2.20.0 [28] jsonlite_1.8.8 DelayedArray_0.30.1 BiocParallel_1.38.0 [31] terra_1.7-78 irlba_2.3.5.1 parallel_4.4.1 [34] R6_2.5.1 stringi_1.8.4 RColorBrewer_1.1-3 [37] reticulate_1.38.0 parallelly_1.37.1 scattermore_1.2 [40] Rcpp_1.0.13 bookdown_0.40 knitr_1.48 [43] future.apply_1.11.2 R.utils_2.12.3 IRanges_2.38.1 [46] Matrix_1.7-0 igraph_2.0.3 tidyselect_1.2.1 [49] rstudioapi_0.16.0 abind_1.4-5 yaml_2.3.9 [52] codetools_0.2-20 listenv_0.9.1 lattice_0.22-6 [55] tibble_3.2.1 plyr_1.8.9 withr_3.0.0 [58] evaluate_0.24.0 future_1.33.2 pillar_1.9.0 [61] MatrixGenerics_1.16.0 checkmate_2.3.1 stats4_4.4.1 [64] plotly_4.10.4 generics_0.1.3 dbscan_1.2-0 [67] sp_2.1-4 S4Vectors_0.42.1 ggplot2_3.5.1 [70] munsell_0.5.1 scales_1.3.0 gtools_3.9.5 [73] globals_0.16.3 glue_1.7.0 lazyeval_0.2.2 [76] tools_4.4.1 GiottoVisuals_0.2.3 data.table_1.15.4 [79] ScaledMatrix_1.12.0 cowplot_1.1.3 grid_4.4.1 [82] tidyr_1.3.1 colorspace_2.1-0 BiocSingular_1.20.0 [85] cli_3.6.3 rsvd_1.0.5 textshaping_0.4.0 [88] fansi_1.0.6 S4Arrays_1.4.1 viridisLite_0.4.2 [91] dplyr_1.1.4 uwot_0.2.2 gtable_0.3.5 [94] R.methodsS3_1.8.2 digest_0.6.36 BiocGenerics_0.50.0 [97] SparseArray_1.4.8 ggrepel_0.9.5 htmlwidgets_1.6.4 [100] farver_2.1.2 htmltools_0.5.8.1 R.oo_1.26.0 [103] lifecycle_1.0.4 httr_1.4.7 "],["interoperability-with-other-frameworks.html", "64 Interoperability with other frameworks 64.1 Load Giotto object 64.2 SpatialExperiment 64.3 Identify top spatially variable genes with nnSVG 64.4 Seurat 64.5 AnnData/SpatialData", " 64 Interoperability with other frameworks Iqra August 7th 2024 Giotto facilitates seamless interoperability with various tools, including Seurat, annData, and SpatialExperiment. Below is a brief introductory tutorial on how Giotto interoperates with these other tools. 64.1 Load Giotto object To begin the interoperability of a Giotto object with other objects, we first load the required libraries and a Giotto mini object. We then continue with the conversion process: library(Giotto) library(GiottoData) Here we load Giotto mini Visium object to continue with the interoperability. gobject &lt;- GiottoData::loadGiottoMini(&quot;visium&quot;) 64.2 SpatialExperiment The Giotto package is interoperable with SpatialExperiment, extending its functionality to include spatial coordinates, images, and image metadata. To start the conversion of a Giotto mini Visium object to a SpatialExperiment object, we first load the required libraries. library(SpatialExperiment) library(ggspavis) library(pheatmap) library(scater) library(scran) library(nnSVG) 64.2.1 Convert Giotto Object to SpatialExperiment Object To convert the Giotto object to a SpatialExperiment object, we use the giottoToSpatialExperiment() function. gspe &lt;- giottoToSpatialExperiment(gobject) The converter function returns a separate SpatialExperiment object for each spatial unit. The output is a list of objects (one for each unit), and we select the first object for downstream use. spe &lt;- gspe[[1]] 64.3 Identify top spatially variable genes with nnSVG We employ the nnSVG package to identify the top spatially variable genes in our SpatialExperiment object.Covariates can be added to our model; in this example, we use Leiden clustering labels as a covariate. These clustering results were initially computed using the Giotto suite and then transferred to the converted SpatialExperiment object. # One of the assays should be &quot;logcounts&quot; # We rename the normalized assay to &quot;logcounts&quot; assayNames(spe)[[2]] &lt;- &quot;logcounts&quot; # Create model matrix for leiden clustering labels X &lt;- model.matrix(~ colData(spe)$leiden_clus) dim(X) ## [1] 624 2 # Run nnSVG spe &lt;- nnSVG(spe, X = X) # Show top 10 features rowData(spe)[order(rowData(spe)$rank)[1:10], ]$feat_ID ## [1] &quot;Ttr&quot; &quot;Zic1&quot; &quot;Tcf7l2&quot; &quot;Prkcd&quot; &quot;Tnnt1&quot; &quot;Ddn&quot; &quot;Hpca&quot; &quot;Shox2&quot; &quot;Cplx2&quot; ## [10] &quot;Slc17a6&quot; 64.3.1 Conversion of SpatialExperiment object back to Giotto We then convert the processed SpatialExperiment object back into a Giotto object for further downstream analysis using the Giotto suite. This is done using the spatialExperimentToGiotto function, where we explicitly specify the spatial network from the SpatialExperiment object. giottoFromSPE &lt;- spatialExperimentToGiotto(spe = spe, python_path = NULL, sp_network = &quot;Delaunay_network&quot;) print(giottoFromSPE) ## An object of class giotto ## &gt;Active spat_unit: cell ## &gt;Active feat_type: rna ## [SUBCELLULAR INFO] ## [AGGREGATE INFO] ## expression ----------------------- ## [cell][rna] raw logcounts scaled_rna_cell ## spatial locations ---------------- ## [cell] raw ## spatial networks ----------------- ## [cell] Delaunay_network ## dim reduction -------------------- ## [cell][rna] pca custom_pca umap custom_umap tsne ## nearest neighbor networks -------- ## [cell][rna] sNN.pca custom_NN spatial_network ## ## ## Use objHistory() to see steps and params used 64.3.2 Plotting top genes from nnSVG in Giotto Now, we visualize the genes previously identified in the SpatialExperiment object using the nnSVG package within the Giotto toolkit, leveraging the converted Giotto object. ext_spatial_genes &lt;- getFeatureMetadata(giottoFromSPE, output = &quot;data.table&quot;) ext_spatial_genes &lt;- ext_spatial_genes[order(ext_spatial_genes$rank)[1:10], ]$feat_ID spatFeatPlot2D(giottoFromSPE, expression_values = &#39;scaled_rna_cell&#39;, feats = ext_spatial_genes[1:4], point_size = 2) 64.4 Seurat The process of conversion between Giotto and Seurat relies on four main functions. giottoToSeuratV4 and seuratToGiottoV4 are designed for Seurat version 4, whereas giottoToSeuratV5 and seuratToGiottoV5 are specifically for Seurat version 5. In this demonstration, we will only cover the conversion between Seurat version 5 and Giotto. 64.4.1 Giotto to Seurat To convert Giotto object to Seurat V5 object, we first load required libraries and use the function giottoToSeuratV5() function library(Seurat) gToS &lt;- giottoToSeuratV5(gobject = gobject, spat_unit = &quot;cell&quot;) 64.5 AnnData/SpatialData To convert the giotto object to annData, we use the Giotto’s function “giottoToAnnData()” gToAnnData &lt;- giottoToAnnData(gobject) ## X (624, 634) ## lay (624, 634) ## &lt;class &#39;scipy.sparse._csr.csr_matrix&#39;&gt; ## X (624, 634) ## lay (624, 634) ## &lt;class &#39;numpy.ndarray&#39;&gt; already nn in giotto for giotto generate nn network in giotto and use it in anndata for visualization use scanpy to generate umap from nn use scanpy to visualize scanpy clustering with umap visuals Optional: similary anndata and preprocessing on anndata QC, Normalization, feature selection, pca now convert giotto use giotto function to visualize umap etc "],["interoperability-with-isolated-tools.html", "65 Interoperability with isolated tools 65.1 Spatial niche trajectory analysis", " 65 Interoperability with isolated tools Wen Wang August 7th 2024 65.1 Spatial niche trajectory analysis 65.1.1 Prepare 65.1.1.1 Dataset download # raw data # giotto # ONTraC input # NT score 65.1.1.2 Installation ONTraC source ~/.bash_profile conda create -y -n ONTraC python=3.11 conda activate ONTraC pip install ONTraC[analysis] 65.1.2 Running 65.1.2.1 Processing with Giotto use the given cell type directly handling multiple sample (Jeff should present this topic on the 2nd day) library(Giotto) # Load dataset giotto_1 = createGiottoObject(expression = &#39;subset_mouse1_slice221_exp.txt&#39;, spatial_locs = &#39;subset_mouse1_slice221_pos.csv&#39;) data1_meta &lt;- read.csv(file = &#39;subset_mouse1_slice221_dataset.csv&#39;) data1_meta &lt;- data1_meta[c(&quot;Cell_Type&quot;)] # we use the given cell type annotation here, you can make your own annotation in process steps rownames(data1_meta) &lt;- giotto_1@cell_metadata$cell$rna$cell_ID giotto_1 &lt;- addCellMetadata(giotto_1, new_metadata = data1_meta) giotto_2 = createGiottoObject(expression = &#39;subset_mouse2_slice201_exp.txt&#39;, spatial_locs = &#39;subset_mouse2_slice201_pos.csv&#39;) data2_meta &lt;- read.csv(file = &#39;subset_mouse2_slice201_dataset.csv&#39;) data2_meta &lt;- data2_meta[c(&quot;Cell_Type&quot;)] # we use the given cell type annotation here, you can make your own annotation in process ste rownames(data2_meta) &lt;- giotto_2@cell_metadata$cell$rna$cell_ID giotto_2 &lt;- addCellMetadata(giotto_2, new_metadata = data2_meta) # Join giotto_objs giotto_obj = joinGiottoObjects(gobject_list = list(giotto_1, giotto_2), gobject_names = c(&#39;mouse1_slice221&#39;, &#39;mouse2_slice201&#39;), # name for each samples join_method = &#39;z_stack&#39;) # Processing the data set using Giotto # skipped here # Generate ONTraC input file pos_df = giotto_obj@spatial_locs$cell[[1]]@coordinates meta_df = giotto_obj@cell_metadata$cell$rna@metaDT output_df = merge(x = pos_df, y = meta_df, by = &#39;cell_ID&#39;)[c(&#39;cell_ID&#39;, &#39;sdimx&#39;, &#39;sdimy&#39;, &#39;Cell_Type&#39;, &#39;list_ID&#39;)] # change the Cell_Type to your own cell type annotation colnames(output_df) = c(&#39;Cell_ID&#39;, &#39;x&#39;, &#39;y&#39;, &#39;Cell_Type&#39;, &#39;Sample&#39;) write.csv(output_df, file=&#39;ONTraC_input.csv&#39;, quote=FALSE, row.names=FALSE) 65.1.2.2 Running ONTraC source ~/.bash_profile conda activate ONTraC ONTraC -d ONTraC_input.csv --preprocessing-dir preprocessing_dir --GNN-dir GNN_dir --NTScore-dir NTScore_dir --device cuda --epochs 1000 -s 42 --patience 100 --min-delta 0.001 --min-epochs 50 --lr 0.03 --hidden-feats 4 -k 6 --modularity-loss-weight 0.3 --regularization-loss-weight 0.1 --purity-loss-weight 300 --beta 0.03 2&gt;&amp;1 | tee merfish_subset.log ONTraC_analysis -o analysis_output/merfish_subset -l merfish_subset.log -d ONTraC_input.csv --preprocessing-dir preprocessing_dir --GNN-dir GNN_dir --NTScore-dir NTScore_dir -r -s 65.1.3 Visualization niche cluster NT score downstream trajectory analysis (Georage should present this topic on the morning session) 65.1.4 NTScore = read.csv(&#39;NTScore_dir/merfish_subset_NTScore/NTScore.csv.gz&#39;)[c(&#39;Cell_NTScore&#39;)] rownames(NTScore) = giotto_obj@cell_metadata$cell$rna$cell_ID giotto_obj &lt;- addCellMetadata(giotto_obj, new_metadata = NTScore) "],["interactivity-with-the-rspatial-ecosystem.html", "66 Interactivity with the R/Spatial ecosystem 66.1 Kriging", " 66 Interactivity with the R/Spatial ecosystem Jeff Sheridan August 7th 2024 66.1 Kriging text "],["contributing-to-giotto.html", "67 Contributing to Giotto 67.1 Contribution guideline", " 67 Contributing to Giotto Jiaji George Chen August 7th 2024 save_dir &lt;- &quot;~/Documents/GitHub/giotto_workshop_2024/img/03_session7&quot; 67.1 Contribution guideline https://drieslab.github.io/Giotto_website/CONTRIBUTING.html "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
